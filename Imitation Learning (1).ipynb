{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ee52fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 13:38:16.592007: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-05 13:38:17.463082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "611df39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(fastmath=True)\n",
    "def get_action(observation):\n",
    "    processed_img = np.copy(observation)\n",
    "    colours = np.array([[170,0,0],[105,230,105],[0,0,0],[101,101,101],[255,255,255]])\n",
    "    \n",
    "    # Crop image\n",
    "    processed_img = processed_img[:-12, 14:-14]\n",
    "    \n",
    "    # Change to a high contrast image with uniform colours\n",
    "    for i, row in enumerate(processed_img):\n",
    "        for j, pixel in enumerate(row):\n",
    "            dists = np.empty(len(colours))\n",
    "            for k, colour in enumerate(colours):\n",
    "                dist = 0\n",
    "                for x, y in zip(pixel, colour):\n",
    "                    dist += np.abs(x-y) ** 2\n",
    "                dists[k] = dist ** (1/2)\n",
    "            min_val = dists[0]\n",
    "            min_ind = 0\n",
    "            for l in range(1, len(colours)):\n",
    "                if dists[l] < min_val:\n",
    "                    min_val = dists[l]\n",
    "                    min_ind = l\n",
    "            processed_img[i,j] = colours[min_ind]\n",
    "            \n",
    "    # To get steering, count road pixels on the left and right of the car.\n",
    "    left_line = processed_img[56:57,:34][0]\n",
    "    right_line = processed_img[56:57,38:][0]\n",
    "    left_count, right_count = 0, 0\n",
    "    for left_pixel, right_pixel in zip(left_line, right_line):\n",
    "        if left_pixel[1] == 101:\n",
    "            left_count += 1\n",
    "        if right_pixel[1] == 101:\n",
    "            right_count += 1\n",
    "    steering = right_count / len(right_line) - left_count / len(left_line)\n",
    "    \n",
    "    # To get gas, count road pixels in front of the car.\n",
    "    middle_line = processed_img.shape[1] / 2\n",
    "    front_line = processed_img[:67,middle_line:middle_line+1]\n",
    "    front_count = 0\n",
    "    for pixel in front_line:\n",
    "        if pixel[0, 1] == 101:\n",
    "            front_count += 1\n",
    "    front_count_norm = front_count / len(front_line)\n",
    "    if steering > 0.75:\n",
    "        gas = front_count_norm * 0.05\n",
    "    elif steering > 0.5:\n",
    "        gas = front_count_norm * 0.1\n",
    "    elif steering > 0.5:\n",
    "        gas = front_count_norm * 0.25\n",
    "    else:\n",
    "        gas = front_count / len(front_line)\n",
    "        \n",
    "    # Use gas and steering to get brake\n",
    "    if (gas > 0.75) and (abs(steering) > 0.75):\n",
    "        brake = gas * 0.975\n",
    "    elif (gas > 0.75) and (abs(steering) > 0.5):\n",
    "        brake = gas * 0.85\n",
    "    elif (gas > 0.75) and (abs(steering) > 0.25):\n",
    "        brake = gas * 0.55\n",
    "    elif (gas > 0.5) and (abs(steering) > 0.75):\n",
    "        brake = gas * 0.975\n",
    "    elif (gas > 0.5) and (abs(steering) > 0.5):\n",
    "        brake = gas * 0.75\n",
    "    elif (gas > 0.5) and (abs(steering) > 0.25):\n",
    "        brake = gas * 0.45\n",
    "    elif (gas > 0.25) and (abs(steering) > 0.75):\n",
    "        brake = gas * 0.975\n",
    "    elif (gas > 0.25) and (abs(steering) > 0.5):\n",
    "        brake = gas * 0.65\n",
    "    elif (gas > 0.25) and (abs(steering) > 0.25):\n",
    "        brake = gas * 0.35\n",
    "    else:\n",
    "        brake = 0.05\n",
    "        \n",
    "    return [steering, 0.5 * gas, brake]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b7d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img):\n",
    "    img = img[:84, 6:90]\n",
    "    return img\n",
    "\n",
    "@nb.njit(fastmath=True)\n",
    "def rgb_to_grey(img):\n",
    "    \"\"\"\n",
    "    Convert an RGB image to greyscale using the weighted method.\n",
    "    \"\"\"\n",
    "    num_rows, num_cols, _ = img.shape\n",
    "    grey_img = np.empty((num_rows, num_cols), dtype=np.uint32)\n",
    "    for i, row in enumerate(img):\n",
    "        for j, rgb_pixel in enumerate(row):\n",
    "            # Compute weighted sum of RGB channels\n",
    "            grey_img[i, j] = 0.2989 * rgb_pixel[0] + 0.5870 * rgb_pixel[1] + 0.1140 * rgb_pixel[2]\n",
    "\n",
    "    return grey_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e822167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_run(env):\n",
    "    observation, info = env.reset()\n",
    "    episode_states = []\n",
    "    episode_actions = []\n",
    "    for _ in range(50):\n",
    "        action = [0.0, 0.0, 0.0]\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "    steps = 0\n",
    "    reward_sum = 0\n",
    "    reward_size = 0\n",
    "    reward_exp = 936\n",
    "    while True:\n",
    "        state_img = np.copy(observation)\n",
    "        state_img = crop(state_img)\n",
    "        state_img = rgb_to_grey(state_img).reshape((84,84,1))\n",
    "        episode_states.append(state_img)\n",
    "            \n",
    "        action = get_action(observation)\n",
    "        episode_actions.append(action)\n",
    "        \n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        steps += 1\n",
    "        if reward > 0:\n",
    "            reward_size = reward\n",
    "            reward_sum += reward\n",
    "            reward_exp = -2.128*(reward_size**2) + 20.65*reward_size + 919.0\n",
    "        if (round(reward_sum) == round(reward_exp)):\n",
    "            return episode_states, episode_actions\n",
    "            break\n",
    "        if steps >= 1500:\n",
    "            return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f1ce1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m states, actions \u001b[38;5;241m=\u001b[39m complete_run(\u001b[43menv\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "states, actions = complete_run(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acadf8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(length):\n",
    "    env = gym.make(\"CarRacing-v2\", domain_randomize=False, autoreset=False)\n",
    "    states = []\n",
    "    actions = []\n",
    "    while len(states) < length:\n",
    "        episode_states, episode_actions = complete_run(env)\n",
    "        if len(episode_states) > 0:\n",
    "            states += episode_states\n",
    "            actions += episode_actions\n",
    "    return np.array(states), np.array(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a8e71d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 04:14:12.568572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 04:14:12.695110: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 04:14:12.695177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 04:14:12.698990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 04:14:12.699061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 04:14:12.699096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 04:14:13.760813: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 04:14:13.761116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 04:14:13.761130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-03 04:14:13.761202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-03 04:14:13.762352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1562 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-05-03 04:14:13.766385: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 724284288 exceeds 10% of free system memory.\n",
      "2023-05-03 04:14:14.276299: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 724284288 exceeds 10% of free system memory.\n",
      "2023-05-03 04:14:14.480183: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 724284288 exceeds 10% of free system memory.\n",
      "2023-05-03 04:14:14.656614: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype double and shape [25662,3]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    }
   ],
   "source": [
    "states, actions = gen_dataset(25_024)\n",
    "states_ds = tf.data.Dataset.from_tensor_slices(states) \n",
    "actions_ds = tf.data.Dataset.from_tensor_slices(actions) \n",
    "dataset = tf.data.Dataset.zip((states_ds, actions_ds))\n",
    "dataset = dataset.batch(32)\n",
    "tf.data.Dataset.save(dataset, \"./dataset3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "894c16c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 10:52:58.631675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-04 10:52:58.845669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-04 10:52:58.845833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-04 10:52:58.851368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-04 10:52:58.851486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-04 10:52:58.851553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-04 10:53:01.191378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-04 10:53:01.191739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-04 10:53:01.191767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-04 10:53:01.191891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-04 10:53:01.191948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1562 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.load(\"./dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4079373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 13:38:29.819191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-05 13:38:29.950213: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-05 13:38:29.950278: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-05 13:38:29.953195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-05 13:38:29.953253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-05 13:38:29.953284: I tensorflow/compile"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 20, 20, 64)        4160      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 20, 20, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 20, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 9, 9, 128)         131200    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 9, 9, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 9, 9, 128)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              6423552   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,714,947\n",
      "Trainable params: 6,712,259\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-05 13:38:31.061891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-05 13:38:31.062054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-05 13:38:31.062070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-05 13:38:31.062128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-05 13:38:31.062164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1562 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "supervised_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=8, strides=4, activation=\"relu\", input_shape=(84,84,1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv2D(128, kernel_size=4, strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(3, activation=\"linear\")\n",
    "])\n",
    "supervised_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "supervised_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3d1ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 04:14:15.428469: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 724284288 exceeds 10% of free system memory.\n",
      "2023-05-03 04:14:15.618579: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype double and shape [25662,3]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-03 04:14:16.344667: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-05-03 04:14:18.161026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-03 04:14:21.519045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-03 04:14:21.574929: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f2c8b20d6c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-03 04:14:21.574964: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2023-05-03 04:14:21.682661: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-03 04:14:22.039202: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 17s 11ms/step - loss: 0.5858\n",
      "Epoch 2/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0205\n",
      "Epoch 3/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0183\n",
      "Epoch 4/15\n",
      "802/802 [==============================] - 8s 9ms/step - loss: 0.0195\n",
      "Epoch 5/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0185\n",
      "Epoch 6/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0190\n",
      "Epoch 7/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0193\n",
      "Epoch 8/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0183\n",
      "Epoch 9/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0175\n",
      "Epoch 10/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0171\n",
      "Epoch 11/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0177\n",
      "Epoch 12/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0155\n",
      "Epoch 13/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0151\n",
      "Epoch 14/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0154\n",
      "Epoch 15/15\n",
      "802/802 [==============================] - 8s 10ms/step - loss: 0.0140\n"
     ]
    }
   ],
   "source": [
    "history = supervised_model.fit(dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55045d01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m guesses \u001b[38;5;241m=\u001b[39m supervised_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mstates\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'states' is not defined"
     ]
    }
   ],
   "source": [
    "guesses = supervised_model.predict(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef43ff03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f0351500d60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_model.load_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87baff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_model.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5381779b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 13:38:43.092329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-05-05 13:38:46.734625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0 reward: 731.7973856208993\n",
      "episode 1 reward: 904.6032786885085\n",
      "episode 2 reward: 766.9528619528476\n",
      "episode 3 reward: 827.5092250922411\n",
      "episode 4 reward: 899.631872509951\n",
      "episode 5 reward: 689.1269841269708\n",
      "episode 6 reward: 646.8397626112667\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v2\", domain_randomize=False)\n",
    "sup_episode_rewards2 = np.zeros(7)\n",
    "for i in range(7):\n",
    "    observation, info = env.reset()\n",
    "    for _ in range(50):\n",
    "        action = [0.0, 0.0, 0.0]\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "    steps = 0\n",
    "    reward_sum = 0\n",
    "    num_rewards = 0\n",
    "    reward_size = 0\n",
    "    reward_exp = 0\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        state_img = crop(observation)\n",
    "        state_img = rgb_to_grey(state_img).reshape((84,84,1))\n",
    "        action = supervised_model.predict(np.array([state_img,]), verbose=0)[0]\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        steps += 1\n",
    "        total_reward += reward\n",
    "        if reward > 0:\n",
    "            reward_size = reward\n",
    "            reward_sum += reward\n",
    "            reward_exp = -2.128*(reward_size**2) + 20.65*reward_size + 919.0\n",
    "        if (terminated) or truncated or (steps >= 1500) or (round(reward_sum) == round(-2.128*(reward_size**2) + 20.65*reward_size + 919.0)):\n",
    "            sup_episode_rewards2[i] = total_reward\n",
    "            print(f\"episode {i} reward: {total_reward}\")\n",
    "#             print(round(-2.128*(reward_size**2) + 20.65*reward_size + 919.0,2))\n",
    "#             print(round(reward_sum,2))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_episode_rewards2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ef0c1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([759.09252669, 900.05283019, 829.18772563, 902.10283401,\n",
       "       760.26315789, 687.05128205, 893.97058824, 685.25477707,\n",
       "       733.02547771, 657.47524752, 696.79810726, 867.68656716,\n",
       "       812.74907749, 794.28571429, 855.35460993, 721.94915254,\n",
       "       527.80701754, 676.24183007, 842.72893773, 706.94805195,\n",
       "       712.07395498,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sup_episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d7ef1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0 reward: 876.7314487632352\n",
      "episode 1 reward: 899.6373134328205\n",
      "episode 2 reward: 767.9283489096398\n",
      "episode 3 reward: 901.9650557620688\n",
      "episode 4 reward: 846.3680781758773\n",
      "episode 5 reward: 772.3139158575906\n",
      "episode 6 reward: 808.0100334447997\n",
      "episode 7 reward: 902.5797833934944\n",
      "episode 8 reward: 796.1564625850241\n",
      "episode 9 reward: 904.5925925925783\n",
      "episode 10 reward: 781.1904761904605\n",
      "episode 11 reward: 900.3571428571272\n",
      "episode 12 reward: 846.8181818181665\n",
      "episode 13 reward: 855.7042253520948\n",
      "episode 14 reward: 795.7284768211822\n",
      "episode 15 reward: 901.1328621907978\n",
      "episode 16 reward: 880.3521126760394\n",
      "episode 17 reward: 651.9879518072191\n",
      "episode 18 reward: 774.5652173912887\n",
      "episode 19 reward: 871.4429530201178\n",
      "episode 20 reward: 819.754098360643\n",
      "episode 21 reward: 792.4172185430361\n",
      "episode 22 reward: 800.2702702702528\n",
      "episode 23 reward: 875.1986754966791\n",
      "episode 24 reward: 689.2565597667527\n",
      "episode 25 reward: 900.507801418428\n",
      "episode 26 reward: 810.5374592833699\n",
      "episode 27 reward: 900.0536231883963\n",
      "episode 28 reward: 727.4299065420402\n",
      "episode 29 reward: 740.4430379746739\n",
      "episode 30 reward: 903.4057553956675\n",
      "episode 31 reward: 899.019926199252\n",
      "episode 32 reward: 898.6795847750778\n",
      "episode 33 reward: 900.0954372623391\n",
      "episode 34 reward: 724.6202531645469\n",
      "episode 35 reward: 902.0272727272572\n",
      "episode 36 reward: 764.4771241829889\n",
      "episode 37 reward: 898.6470588235122\n",
      "episode 38 reward: 863.904109589024\n",
      "episode 39 reward: 683.8161993769316\n",
      "episode 40 reward: 859.8611111110927\n",
      "episode 41 reward: 902.4328621907979\n",
      "episode 42 reward: 639.2192691029779\n",
      "episode 43 reward: 899.9536231883961\n",
      "episode 44 reward: 837.8621908127062\n",
      "episode 45 reward: 906.1371647509504\n",
      "episode 46 reward: 899.8812030075013\n",
      "episode 47 reward: 876.4285714285552\n",
      "episode 48 reward: 715.1265822784706\n",
      "episode 49 reward: 755.4672897196086\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v2\", domain_randomize=False)\n",
    "episode_rewards = np.zeros(50)\n",
    "for i in range(50):\n",
    "    observation, info = env.reset()\n",
    "    for _ in range(50):\n",
    "        action = [0.0, 0.0, 0.0]\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "    steps = 0\n",
    "    reward_sum = 0\n",
    "    num_rewards = 0\n",
    "    reward_size = 0\n",
    "    reward_exp = 0\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        action = get_action(observation)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        steps += 1\n",
    "        total_reward += reward\n",
    "        if reward > 0:\n",
    "            reward_size = reward\n",
    "            reward_sum += reward\n",
    "            reward_exp = -2.128*(reward_size**2) + 20.65*reward_size + 919.0\n",
    "\n",
    "        if (steps >= 1500) or terminated or truncated or (round(reward_sum) == round(-2.128*(reward_size**2) + 20.65*reward_size + 919.0)):\n",
    "            episode_rewards[i] = total_reward\n",
    "            print(f\"episode {i} reward: {total_reward}\")\n",
    "#             print(round(-2.128*(reward_size**2) + 20.65*reward_size + 919.0,2))\n",
    "#             print(round(reward_sum,2))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf59a106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0 reward: -32.728937728938234\n",
      "episode 1 reward: -34.06810035842362\n",
      "episode 2 reward: -29.362934362934805\n",
      "episode 3 reward: -41.70846394984401\n",
      "episode 4 reward: -30.714285714286216\n",
      "episode 5 reward: -34.501779359431175\n",
      "episode 6 reward: -34.71631205673827\n",
      "episode 7 reward: -39.80519480519551\n",
      "episode 8 reward: -35.520446096654894\n",
      "episode 9 reward: -41.875000000000675\n",
      "episode 10 reward: -42.368421052632364\n",
      "episode 11 reward: -36.379310344828305\n",
      "episode 12 reward: -41.031746031746714\n",
      "episode 13 reward: -37.176870748300004\n",
      "episode 14 reward: -41.30872483221547\n",
      "episode 15 reward: -35.35087719298303\n",
      "episode 16 reward: -34.50177935943123\n",
      "episode 17 reward: -45.4643962848305\n",
      "episode 18 reward: -29.06593406593455\n",
      "episode 19 reward: -28.823529411765154\n",
      "episode 20 reward: -29.61538461538518\n",
      "episode 21 reward: -39.98381877022721\n",
      "episode 22 reward: -37.238267148015076\n",
      "episode 23 reward: -42.19471947194793\n",
      "episode 24 reward: -36.1764705882359\n",
      "episode 25 reward: -39.25087108014003\n",
      "episode 26 reward: -40.16129032258133\n",
      "episode 27 reward: -34.39393939393995\n",
      "episode 28 reward: -37.372881355932826\n",
      "episode 29 reward: -37.44604316546833\n",
      "episode 30 reward: -40.12195121951302\n",
      "episode 31 reward: -38.333333333334046\n",
      "episode 32 reward: -34.50177935943123\n",
      "episode 33 reward: -40.20547945205549\n",
      "episode 34 reward: -30.114503816794347\n",
      "episode 35 reward: -33.5665529010245\n",
      "episode 36 reward: -35.07490636704188\n",
      "episode 37 reward: -31.39575971731502\n",
      "episode 38 reward: -33.628158844765856\n",
      "episode 39 reward: -37.857142857143494\n",
      "episode 40 reward: -40.20547945205554\n",
      "episode 41 reward: -40.33762057877882\n",
      "episode 42 reward: -40.16129032258138\n",
      "episode 43 reward: -32.28222996515736\n",
      "episode 44 reward: -30.94306049822114\n",
      "episode 45 reward: -34.79933110367957\n",
      "episode 46 reward: -42.20496894410013\n",
      "episode 47 reward: -34.28571428571481\n",
      "episode 48 reward: -31.32958801498183\n",
      "episode 49 reward: -40.205479452055464\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v2\", domain_randomize=False, render_mode=True)\n",
    "episode_rewards = np.zeros(50)\n",
    "for i in range(50):\n",
    "    observation, info = env.reset()\n",
    "    for _ in range(50):\n",
    "        action = [0.0, 0.0, 0.0]\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "    steps = 0\n",
    "    reward_sum = 0\n",
    "    num_rewards = 0\n",
    "    reward_size = 0\n",
    "    reward_exp = 0\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        gas = np.random.rand()\n",
    "        brake = np.random.rand()\n",
    "        steering = 2 * np.random.rand() - 1\n",
    "        action = [steering, gas, brake]\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        steps += 1\n",
    "        total_reward += reward\n",
    "        if reward > 0:\n",
    "            reward_size = reward\n",
    "            reward_sum += reward\n",
    "            reward_exp = -2.128*(reward_size**2) + 20.65*reward_size + 919.0\n",
    "\n",
    "        if (steps >= 1500) or terminated or truncated or (round(reward_sum) == round(-2.128*(reward_size**2) + 20.65*reward_size + 919.0)):\n",
    "            episode_rewards[i] = total_reward\n",
    "            print(f\"episode {i} reward: {total_reward}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd8c58d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([876.73144876, 899.63731343, 767.92834891, 901.96505576,\n",
       "       846.36807818, 772.31391586, 808.01003344, 902.57978339,\n",
       "       796.15646259, 904.59259259, 781.19047619, 900.35714286,\n",
       "       846.81818182, 855.70422535, 795.72847682, 901.13286219,\n",
       "       880.35211268, 651.98795181, 774.56521739, 871.44295302,\n",
       "       819.75409836, 792.41721854, 800.27027027, 875.1986755 ,\n",
       "       689.25655977, 900.50780142, 810.53745928, 900.05362319,\n",
       "       727.42990654, 740.44303797, 903.4057554 , 899.0199262 ,\n",
       "       898.67958478, 900.09543726, 724.62025316, 902.02727273,\n",
       "       764.47712418, 898.64705882, 863.90410959, 683.81619938,\n",
       "       859.86111111, 902.43286219, 639.2192691 , 899.95362319,\n",
       "       837.86219081, 906.13716475, 899.88120301, 876.42857143,\n",
       "       715.12658228, 755.46728972])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51860fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-32.72893773, -34.06810036, -29.36293436, -41.70846395,\n",
       "       -30.71428571, -34.50177936, -34.71631206, -39.80519481,\n",
       "       -35.5204461 , -41.875     , -42.36842105, -36.37931034,\n",
       "       -41.03174603, -37.17687075, -41.30872483, -35.35087719,\n",
       "       -34.50177936, -45.46439628, -29.06593407, -28.82352941,\n",
       "       -29.61538462, -39.98381877, -37.23826715, -42.19471947,\n",
       "       -36.17647059, -39.25087108, -40.16129032, -34.39393939,\n",
       "       -37.37288136, -37.44604317, -40.12195122, -38.33333333,\n",
       "       -34.50177936, -40.20547945, -30.11450382, -33.5665529 ,\n",
       "       -35.07490637, -31.39575972, -33.62815884, -37.85714286,\n",
       "       -40.20547945, -40.33762058, -40.16129032, -32.28222997,\n",
       "       -30.9430605 , -34.7993311 , -42.20496894, -34.28571429,\n",
       "       -31.32958801, -40.20547945])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ddd9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    action = get_action(observation)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    steps += 1\n",
    "    total_reward += reward\n",
    "    if reward > 0:\n",
    "        reward_size = reward\n",
    "        reward_sum += reward\n",
    "        reward_exp = -2.128*(reward_size**2) + 20.65*reward_size + 919.0\n",
    "\n",
    "    if (round(reward_sum) == round(-2.128*(reward_size**2) + 20.65*reward_size + 919.0)):\n",
    "        print(round(-2.128*(reward_size**2) + 20.65*reward_size + 919.0,2))\n",
    "        print(round(reward_sum,2))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72710c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.full(34,56)\n",
    "left_y_vals = np.array(range(14,48))\n",
    "right_y_vals = np.array(range(48,82))\n",
    "\n",
    "y_vals = np.full(67,48)\n",
    "top_x_vals = np.array(range(0,67))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00326a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(96-28)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "394e0edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "34+14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc4085c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(observation)\n",
    "plt.plot(left_y_vals, x_vals, color=\"white\")\n",
    "plt.plot(right_y_vals, x_vals, color=\"white\")\n",
    "plt.plot(y_vals, top_x_vals, color=\"white\", label=\"line of sight\")\n",
    "plt.legend(facecolor=\"black\", labelcolor=\"white\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"pixel_counting.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f8bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepRL",
   "language": "python",
   "name": "deeprl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
