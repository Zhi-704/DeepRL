{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(fastmath=True)\n",
    "def contrast_img(img, colours):\n",
    "    \"\"\"\n",
    "    Return the high-contrast image,\n",
    "    with each pixel set as the closest high-contrast colour.\n",
    "    \"\"\"\n",
    "    rgb_img = np.copy(img)\n",
    "    for i, row in enumerate(rgb_img):\n",
    "        for j, rgb_pixel in enumerate(row):\n",
    "            dists = np.empty(len(colours))\n",
    "            for k, colour in enumerate(colours):\n",
    "                dist = 0\n",
    "                for x, y in zip(rgb_pixel, colour):\n",
    "                    dist += np.abs(x-y) ** 2\n",
    "                dists[k] = dist ** (1/2)\n",
    "            min_val = dists[0]\n",
    "            min_ind = 0\n",
    "            for l in range(1, len(colours)):\n",
    "                if dists[l] < min_val:\n",
    "                    min_val = dists[l]\n",
    "                    min_ind = l\n",
    "            rgb_img[i,j] = colours[min_ind]\n",
    "    return rgb_img\n",
    "\n",
    "\n",
    "def agent_process_img(img, crop=\"box\", contrast=True):\n",
    "    \"\"\"\n",
    "    Pre-process the image\n",
    "    \"\"\"\n",
    "    if crop == \"box\":\n",
    "        # crop unnecessary pixels\n",
    "        img = img[12:-12, 12:-12]\n",
    "        \n",
    "    if contrast:\n",
    "        # Set each pixel colour as its closest high-contrast colour\n",
    "        colours = np.array([[170,0,0],[105,230,105],[0,0,0],[101,101,101],[255,255,255]])\n",
    "        img = contrast_img(img, colours)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img):\n",
    "    img = img[:84, 6:90] \n",
    "    return img\n",
    "\n",
    "@nb.njit(fastmath=True)\n",
    "def rgb_to_grey(img):\n",
    "    \"\"\"\n",
    "    Convert an RGB image to greyscale using the weighted method.\n",
    "    \"\"\"\n",
    "    num_rows, num_cols, _ = img.shape\n",
    "    grey_img = np.empty((num_rows, num_cols), dtype=np.uint8)\n",
    "    for i, row in enumerate(img):\n",
    "        for j, rgb_pixel in enumerate(row):\n",
    "            # Compute weighted sum of RGB channels\n",
    "            grey_img[i, j] = 0.2989 * rgb_pixel[0] + 0.5870 * rgb_pixel[1] + 0.1140 * rgb_pixel[2]\n",
    "\n",
    "    return grey_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(fastmath=True)\n",
    "def get_steering(processed_img, line_ind):\n",
    "    \"\"\"Count road pixels on the left and right of the car.\"\"\"\n",
    "    left_line = processed_img[line_ind:line_ind+1,:34][0]\n",
    "    right_line = processed_img[line_ind:line_ind+1,38:][0]\n",
    "    left_count, right_count = 0, 0\n",
    "    for left_pixel, right_pixel in zip(left_line, right_line):\n",
    "        if left_pixel[1] == 101:\n",
    "            left_count += 1\n",
    "        if right_pixel[1] == 101:\n",
    "            right_count += 1\n",
    "    \n",
    "    return right_count / len(right_line) - left_count / len(left_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(length):\n",
    "    env = gym.make(\"CarRacing-v2\", domain_randomize=False, autoreset=False)\n",
    "    states = []\n",
    "    actions = []\n",
    "    colours = np.array([[170,0,0],[105,230,105],[0,0,0],[101,101,101],[255,255,255]])\n",
    "    while len(states) < length:\n",
    "        episode_states = []\n",
    "        episode_actions = []\n",
    "        observation, info = env.reset()\n",
    "        for _ in range(50):\n",
    "            action = [0.0, 0.0, 0.0]\n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "        steps = 0\n",
    "        reward_sum = 0\n",
    "        reward_size = 0\n",
    "        reward_exp = 0\n",
    "        while True:\n",
    "            state_img = np.copy(observation)\n",
    "            state_img = crop(state_img)\n",
    "            state_img = rgb_to_grey(state_img).reshape((84,84,1))\n",
    "            episode_states.append(state_img)\n",
    "            \n",
    "            agent_img = np.copy(observation)\n",
    "            agent_img = agent_process_img(agent_img)\n",
    "            steering = get_steering(agent_img,56)\n",
    "            action = [steering, 0.025+np.random.rand()*0.950, np.random.rand()*0.125]\n",
    "            episode_actions.append(action)\n",
    "            \n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "            steps += 1\n",
    "            if reward > 0:\n",
    "                reward_size = reward\n",
    "                reward_sum += reward\n",
    "                reward_exp = -2.128*(reward_size**2) + 20.65*reward_size + 919.0\n",
    "                \n",
    "            if (round(reward_sum) == round(reward_exp)):\n",
    "                states += episode_states\n",
    "                actions += episode_actions\n",
    "                break\n",
    "            if steps >= 2000:\n",
    "                break\n",
    "    return np.array(states), np.array(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions = gen_dataset(10_000)\n",
    "states_ds = tf.data.Dataset.from_tensor_slices(states) \n",
    "actions_ds = tf.data.Dataset.from_tensor_slices(actions) \n",
    "dataset = tf.data.Dataset.zip((states_ds, actions_ds))\n",
    "dataset = dataset.batch(64)\n",
    "tf.data.Dataset.save(dataset, \"./dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=8, input_shape=(84,84,1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=4),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(3, activation=\"linear\")\n",
    "])\n",
    "supervised_model.compile(optimizer=\"adam\", loss=\"huber\")\n",
    "supervised_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = supervised_model.fit(dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = supervised_model.predict(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10000,1000):\n",
    "    print(f\"guess = {guesses[i]}\")\n",
    "    print(f\"actual = {actions[i]}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_model.save_weights('./checkpoints/my_checkpoint')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
