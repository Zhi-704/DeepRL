{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numba as nb\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up environment\n",
    "env = gym.make('CarRacing-v2', continuous=False)\n",
    "env.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img):\n",
    "    img = img[:84, 6:90] # CarRacing-v2-specific cropping\n",
    "    # img = cv2.resize(img, dsize=(84, 84)) # or you can simply use rescaling\n",
    "    \n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "    return img\n",
    "\n",
    "@nb.njit(fastmath=True)\n",
    "def rgb_to_grey(img):\n",
    "    \"\"\"\n",
    "    Convert an RGB image to greyscale using the weighted method.\n",
    "    \"\"\"\n",
    "    num_rows, num_cols, _ = img.shape\n",
    "    grey_img = np.empty((num_rows, num_cols), dtype=np.uint8)\n",
    "    for i, row in enumerate(img):\n",
    "        for j, rgb_pixel in enumerate(row):\n",
    "            # Compute weighted sum of RGB channels\n",
    "            grey_img[i, j] = 0.2989 * rgb_pixel[0] + 0.5870 * rgb_pixel[1] + 0.1140 * rgb_pixel[2]\n",
    "\n",
    "    return grey_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEnv(gym.Wrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        skip_frames=4,\n",
    "        stack_frames=4,\n",
    "        initial_no_op=50,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(ImageEnv, self).__init__(env, **kwargs)\n",
    "        self.initial_no_op = initial_no_op\n",
    "        self.skip_frames = skip_frames\n",
    "        self.stack_frames = stack_frames\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        # reset the original environment\n",
    "        s, info = self.env.reset()\n",
    "\n",
    "        # Do nothing for the next `self.initial_no_op` steps\n",
    "        for i in range(self.initial_no_op):\n",
    "            s, r, terminated, truncated, info = self.env.step(0)\n",
    "\n",
    "        # crop image\n",
    "        s = crop(s)\n",
    "        s = rgb_to_grey(s)\n",
    "        \n",
    "\n",
    "        # initial observation is simply a copy of the frame 's'\n",
    "        self.stacked_state = np.tile(s, (self.stack_frames, 1, 1))\n",
    "        return self.stacked_state, info\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Take an action for self.skip_frames steps\n",
    "        reward = 0\n",
    "        for _ in range(self.skip_frames):\n",
    "            s, r, terminated, truncated, info = self.env.step(action)\n",
    "            reward += r\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        s = crop(s)\n",
    "        s = rgb_to_grey(s)\n",
    "\n",
    "        # push the current frame 's' at the end of self.stacked_state\n",
    "        self.stacked_state = np.concatenate((self.stacked_state[1:], s[np.newaxis]), axis=0)\n",
    "\n",
    "        return self.stacked_state, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of an observation:  (4, 84, 84)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v2', continuous=False)\n",
    "env = ImageEnv(env)\n",
    "\n",
    "s, _ = env.reset()\n",
    "print(\"The shape of an observation: \", s.shape)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for i in range(4):\n",
    "    axes[i].imshow(s[i], cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNActionValue(tf.keras.Model):\n",
    "    def __init__(self, state_dim, action_dim, activation=tf.nn.relu):\n",
    "        super(CNNActionValue, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(16, kernel_size=8, strides=4, input_shape=state_dim) # [N, 4, 84, 84] -> [N, 16, 20, 20]\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, kernel_size=4, strides=2) # [N, 16, 20, 20] -> [N, 32, 9, 9]\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(256, activation=activation)\n",
    "        self.fc2 = tf.keras.layers.Dense(action_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.nn.relu(self.conv1(x))\n",
    "        x = tf.nn.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Loss=-0.0166\n",
      "Iteration 2: Loss=-0.5778\n",
      "Iteration 3: Loss=-1.6386\n",
      "Iteration 4: Loss=-3.6169\n",
      "Iteration 5: Loss=-7.0159\n",
      "Iteration 6: Loss=-12.4997\n",
      "Iteration 7: Loss=-20.8860\n",
      "Iteration 8: Loss=-33.1798\n",
      "Iteration 9: Loss=-50.5604\n",
      "Iteration 10: Loss=-74.4021\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate some random input data\n",
    "input_data = np.random.rand(32, 84, 84, 4).astype(np.float32)\n",
    "\n",
    "input_data = tf.convert_to_tensor(input_data)\n",
    "\n",
    "# Step 2: Instantiate the model\n",
    "model = CNNActionValue(state_dim=(4, 84, 84), action_dim=10)\n",
    "\n",
    "# Step 3: Test the model's output\n",
    "output = model.call(input_data)\n",
    "assert output.shape == (32, 10), f\"Expected output shape (32, 10), but got {output.shape}\"\n",
    "\n",
    "# Step 4: Test the model's differentiability\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(input_data)\n",
    "    output = model.call(input_data)\n",
    "grads = tape.gradient(output, input_data)\n",
    "assert grads.shape == input_data.shape, f\"Expected gradient shape {input_data.shape}, but got {grads.shape}\"\n",
    "\n",
    "# Step 5: Update the model parameters\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "for i in range(10):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(model.trainable_variables)\n",
    "        output = model.call(input_data)\n",
    "        loss = tf.reduce_mean(output)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    # Step 6: Repeat the process for a few iterations\n",
    "    print(f\"Iteration {i+1}: Loss={loss.numpy():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, state_dim, action_dim, max_size=int(1e5)):\n",
    "        self.s = np.zeros((max_size, *state_dim), dtype=np.float32)\n",
    "        self.a = np.zeros((max_size, *action_dim), dtype=np.int64)\n",
    "        self.r = np.zeros((max_size, 1), dtype=np.float32)\n",
    "        self.s_prime = np.zeros((max_size, *state_dim), dtype=np.float32)\n",
    "        self.terminated = np.zeros((max_size, 1), dtype=np.float32)\n",
    "\n",
    "        self.ptr = 0\n",
    "        self.size = 0\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def update(self, s, a, r, s_prime, terminated):\n",
    "        self.s[self.ptr] = s\n",
    "        self.a[self.ptr] = a\n",
    "        self.r[self.ptr] = r\n",
    "        self.s_prime[self.ptr] = s_prime\n",
    "        self.terminated[self.ptr] = terminated\n",
    "        \n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        ind = np.random.randint(0, self.size, batch_size)\n",
    "        return (\n",
    "            tf.constant(self.s[ind], dtype=tf.float32),\n",
    "            tf.constant(self.a[ind], dtype=tf.int32),\n",
    "            tf.constant(self.r[ind], dtype=tf.float32),\n",
    "            tf.constant(self.s_prime[ind], dtype=tf.float32),\n",
    "            tf.constant(self.terminated[ind], dtype=tf.float32),\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        learning_rate=0.00025,\n",
    "        epsilon=1.0,\n",
    "        epsilon_min=0.1,\n",
    "        gamma=0.99,\n",
    "        batch_size=32,\n",
    "        warmup_steps=5000,\n",
    "        buffer_size=int(1e5),\n",
    "        target_update_interval=10000,\n",
    "    ):\n",
    "        self.action_dim = action_dim\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.target_update_interval = target_update_interval\n",
    "\n",
    "        self.network = CNNActionValue(state_dim, action_dim)\n",
    "        self.target_network = CNNActionValue(state_dim, action_dim)\n",
    "        self.target_network.set_weights(self.network.get_weights())\n",
    "        self.optimizer = tf.keras.optimizers.RMSprop(learning_rate)\n",
    "\n",
    "        self.buffer = ReplayBuffer(state_dim, (1, ), buffer_size)\n",
    "        self.device = tf.device('gpu' if tf.test.is_built_with_cuda() else 'cpu')\n",
    "\n",
    "        self.total_steps = 0\n",
    "        self.epsilon_decay = (epsilon - epsilon_min) / 1e6\n",
    "\n",
    "    # @tf.function\n",
    "    # def act(self, x, training=True):\n",
    "    #     self.network.trainable(training)\n",
    "    #     if training and ((tf.random.uniform([]) < self.epsilon) or (self.total_steps < self.warmup_steps)):\n",
    "    #         a = tf.random.uniform([], maxval=self.action_dim, dtype=tf.int64)\n",
    "    #         # np.random.randint(self.action_dim)\n",
    "    #     else:\n",
    "    #         x = tf.expand_dims(x, axis=0)\n",
    "    #         q = self.network(x)\n",
    "    #         a = tf.argmax(q, axis=-1)\n",
    "    #     return a.numpy()[0]\n",
    "\n",
    "    @tf.function\n",
    "    def act(self, x, training=True):\n",
    "        self.network.trainable = training\n",
    "        if training and ((np.random.rand() < self.epsilon) or (self.total_steps < self.warmup_steps)):\n",
    "            a = np.random.randint(0, self.action_dim)\n",
    "        else:\n",
    "            x = tf.expand_dims(tf.convert_to_tensor(x, dtype=tf.float32), axis=0)\n",
    "            q = self.network(x)\n",
    "            a = tf.argmax(q, axis=1).numpy()[0]\n",
    "        return a\n",
    "    \n",
    "     # def act(self, state, training=True):\n",
    "    #     if training and np.random.rand() < self.epsilon:\n",
    "    #         # Select a random action with probability epsilon\n",
    "    #         action = np.random.randint(self.action_dim)\n",
    "    #     else:\n",
    "    #         # Select the action with the highest Q-value\n",
    "    #         state = tf.expand_dims(state, axis=0)\n",
    "    #         q_values = self.network(state, training=False)\n",
    "    #         action = tf.argmax(q_values, axis=1).numpy()[0]\n",
    "    #     return action\n",
    "    \n",
    "    \n",
    "    # def act(self, x, training=True):\n",
    "    #     if not training:\n",
    "    #         tf.keras.backend.set_learning_phase(False)\n",
    "    #     else:\n",
    "    #         tf.keras.backend.set_learning_phase(True)\n",
    "\n",
    "    #     if training and ((np.random.rand() < self.epsilon) or (self.total_steps < self.warmup_steps)):\n",
    "    #         a = np.random.randint(0, self.action_dim)\n",
    "    #     else:\n",
    "    #         x = tf.expand_dims(tf.convert_to_tensor(x, dtype=tf.float32), 0)\n",
    "    #         q = self.network(x, training=training)\n",
    "    #         a = tf.argmax(q[0]).numpy()\n",
    "    #     return a\n",
    "\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def learn(self):\n",
    "        s, a, r, s_prime, terminated = self.buffer.sample(self.batch_size)\n",
    "        s = tf.convert_to_tensor(s)\n",
    "        a = tf.convert_to_tensor(a)\n",
    "        r = tf.convert_to_tensor(r)\n",
    "        s_prime = tf.convert_to_tensor(s_prime)\n",
    "        terminated = tf.convert_to_tensor(terminated)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            next_q = self.target_network(s_prime)\n",
    "            td_target = r + (1. - terminated) * self.gamma * tf.reduce_max(next_q, axis=-1, keepdims=True)\n",
    "            q_values = tf.gather_nd(self.network(s), tf.stack((tf.range(a.shape[0]), a[:, 0]), axis=1))\n",
    "            loss = tf.reduce_mean(tf.square(q_values - tf.stop_gradient(td_target)))\n",
    "\n",
    "        gradients = tape.gradient(loss, self.network.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_variables))\n",
    "\n",
    "        result = {\n",
    "            'total_steps': self.total_steps,\n",
    "            'value_loss': loss.numpy(),\n",
    "        }\n",
    "        return result\n",
    "    \n",
    "    def process(self, transition):\n",
    "        result = {}\n",
    "        self.total_steps += 1\n",
    "        self.buffer.update(*transition)\n",
    "\n",
    "        if self.total_steps > self.warmup_steps:\n",
    "            result = self.learn()\n",
    "\n",
    "        if self.total_steps % self.target_update_interval == 0:\n",
    "            self.target_network.set_weights(self.network.get_weights())\n",
    "        self.epsilon -= self.epsilon_decay\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2', continuous=False)\n",
    "env = ImageEnv(env)\n",
    "\n",
    "max_steps = int(250000)\n",
    "eval_interval = 10000\n",
    "state_dim = (4, 84, 84) \n",
    "action_dim = env.action_space.n\n",
    "\n",
    "agent = DQN(state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(n_evals=5):\n",
    "    eval_env = gym.make('CarRacing-v2', continuous=False)\n",
    "    eval_env = ImageEnv(eval_env)\n",
    "    \n",
    "    scores = 0\n",
    "    for i in range(n_evals):\n",
    "        (s, _), done, ret = eval_env.reset(), False, 0\n",
    "        while not done:\n",
    "            a = agent.act(s, training=False)\n",
    "            s_prime, r, terminated, truncated, info = eval_env.step(a)\n",
    "            s = s_prime\n",
    "            ret += r\n",
    "            done = terminated or truncated\n",
    "        scores += ret\n",
    "    return np.round(scores / n_evals, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "\n",
    "# history = {'Step': [], 'AvgReturn': []}\n",
    "\n",
    "# (s, _) = env.reset()\n",
    "# while True:\n",
    "#     a = agent.act(s)\n",
    "#     s_prime, r, terminated, truncated, info = env.step(a)\n",
    "#     result = agent.process((s, a, r, s_prime, terminated))  # You can track q-losses over training from `result` variable.\n",
    "    \n",
    "#     s = s_prime\n",
    "#     if terminated or truncated:\n",
    "#         s, _ = env.reset()\n",
    "        \n",
    "#     if agent.total_steps % eval_interval == 0:\n",
    "#         ret = evaluate()\n",
    "#         history['Step'].append(agent.total_steps)\n",
    "#         history['AvgReturn'].append(ret)\n",
    "        \n",
    "#         clear_output()\n",
    "#         plt.figure(figsize=(8, 5))\n",
    "#         plt.plot(history['Step'], history['AvgReturn'], 'r-')\n",
    "#         plt.xlabel('Step', fontsize=16)\n",
    "#         plt.ylabel('AvgReturn', fontsize=16)\n",
    "#         plt.xticks(fontsize=14)\n",
    "#         plt.yticks(fontsize=14)\n",
    "#         plt.grid(axis='y')\n",
    "#         plt.show()\n",
    "        \n",
    "#         agent.network.save_weights('dqn.h5')\n",
    "    \n",
    "#     if agent.total_steps > max_steps:\n",
    "#         break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\sebsj\\AppData\\Local\\Temp\\ipykernel_22668\\2188534290.py\", line 52, in act  *\n        q = self.network(x)\n    File \"c:\\Users\\sebsj\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\sebsj\\AppData\\Local\\Temp\\__autograph_generated_filemnxwfn3k.py\", line 10, in tf__call\n        x = ag__.converted_call(ag__.ld(tf).nn.relu, (ag__.converted_call(ag__.ld(self).conv1, (ag__.ld(x),), None, fscope),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'cnn_action_value_1' (type CNNActionValue).\n    \n    in user code:\n    \n        File \"C:\\Users\\sebsj\\AppData\\Local\\Temp\\ipykernel_22668\\1781783688.py\", line 11, in call  *\n            x = tf.nn.relu(self.conv1(x))\n        File \"c:\\Users\\sebsj\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer 'conv2d_2' (type Conv2D).\n        \n        Negative dimension size caused by subtracting 8 from 4 for '{{node cnn_action_value_1/conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 4, 4, 1], use_cudnn_on_gpu=true](ExpandDims, cnn_action_value_1/conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [1,4,84,84], [8,8,84,16].\n        \n        Call arguments received by layer 'conv2d_2' (type Conv2D):\n          • inputs=tf.Tensor(shape=(1, 4, 84, 84), dtype=float32)\n    \n    \n    Call arguments received by layer 'cnn_action_value_1' (type CNNActionValue):\n      • x=tf.Tensor(shape=(1, 4, 84, 84), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m frames\u001b[39m.\u001b[39mappend(eval_env\u001b[39m.\u001b[39mrender())\n\u001b[0;32m      9\u001b[0m s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m---> 10\u001b[0m a \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mact(s, training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     11\u001b[0m s_prime, r, terminated, truncated, info \u001b[39m=\u001b[39m eval_env\u001b[39m.\u001b[39mstep(a)\n\u001b[0;32m     12\u001b[0m s \u001b[39m=\u001b[39m s_prime\n",
      "File \u001b[1;32mc:\\Users\\sebsj\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileet_m63yg.py:30\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__act\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m     28\u001b[0m a \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m q \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mand_(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mld(training), \u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mor_(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(np)\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand, (), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39m<\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mepsilon, \u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtotal_steps \u001b[39m<\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mwarmup_steps)), if_body, else_body, get_state, set_state, (\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileet_m63yg.py:26\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__act.<locals>.else_body\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mnonlocal\u001b[39;00m x, a\n\u001b[0;32m     25\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mexpand_dims, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mconvert_to_tensor, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mfloat32), fscope),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), fscope)\n\u001b[1;32m---> 26\u001b[0m q \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mnetwork, (ag__\u001b[39m.\u001b[39;49mld(x),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     27\u001b[0m a \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39margmax, (ag__\u001b[39m.\u001b[39mld(q),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), fscope)\u001b[39m.\u001b[39mnumpy, (), \u001b[39mNone\u001b[39;00m, fscope)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sebsj\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filemnxwfn3k.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconv1, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     11\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconv2, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mflatten, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\sebsj\\AppData\\Local\\Temp\\ipykernel_22668\\2188534290.py\", line 52, in act  *\n        q = self.network(x)\n    File \"c:\\Users\\sebsj\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\sebsj\\AppData\\Local\\Temp\\__autograph_generated_filemnxwfn3k.py\", line 10, in tf__call\n        x = ag__.converted_call(ag__.ld(tf).nn.relu, (ag__.converted_call(ag__.ld(self).conv1, (ag__.ld(x),), None, fscope),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'cnn_action_value_1' (type CNNActionValue).\n    \n    in user code:\n    \n        File \"C:\\Users\\sebsj\\AppData\\Local\\Temp\\ipykernel_22668\\1781783688.py\", line 11, in call  *\n            x = tf.nn.relu(self.conv1(x))\n        File \"c:\\Users\\sebsj\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer 'conv2d_2' (type Conv2D).\n        \n        Negative dimension size caused by subtracting 8 from 4 for '{{node cnn_action_value_1/conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 4, 4, 1], use_cudnn_on_gpu=true](ExpandDims, cnn_action_value_1/conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [1,4,84,84], [8,8,84,16].\n        \n        Call arguments received by layer 'conv2d_2' (type Conv2D):\n          • inputs=tf.Tensor(shape=(1, 4, 84, 84), dtype=float32)\n    \n    \n    Call arguments received by layer 'cnn_action_value_1' (type CNNActionValue):\n      • x=tf.Tensor(shape=(1, 4, 84, 84), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "eval_env = gym.make('CarRacing-v2', continuous=False, render_mode='rgb_array')\n",
    "eval_env = ImageEnv(eval_env)\n",
    "\n",
    "frames = []\n",
    "scores = 0\n",
    "(s, _), done, ret = eval_env.reset(), False, 0\n",
    "while not done:\n",
    "    frames.append(eval_env.render())\n",
    "    s = s.astype(np.float32)\n",
    "    a = agent.act(s, training=False)\n",
    "    s_prime, r, terminated, truncated, info = eval_env.step(a)\n",
    "    s = s_prime\n",
    "    ret += r\n",
    "    done = terminated or truncated\n",
    "scores += ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(imgs, video_name, _return=True):\n",
    "    import cv2\n",
    "    import os\n",
    "    import string\n",
    "    import random\n",
    "    \n",
    "    if video_name is None:\n",
    "        video_name = ''.join(random.choice(string.ascii_letters) for i in range(18)) + '.webm'\n",
    "    height, width, layers = imgs[0].shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'VP90')\n",
    "    video = cv2.VideoWriter(video_name, fourcc, 10, (width, height))\n",
    "    \n",
    "    for img in imgs:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        video.write(img)\n",
    "    video.release()\n",
    "    if _return:\n",
    "        from IPython.display import Video\n",
    "        return Video(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "animate() missing 1 required positional argument: 'video_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m animate(frames)\n",
      "\u001b[1;31mTypeError\u001b[0m: animate() missing 1 required positional argument: 'video_name'"
     ]
    }
   ],
   "source": [
    "animate(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
