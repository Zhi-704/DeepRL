{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numba as nb\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up environment\n",
    "env = gym.make('CarRacing-v2', continuous=False)\n",
    "env.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implements this paper: https://arxiv.org/pdf/1312.5602.pdf "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img):\n",
    "    img = img[:84, 6:90] # CarRacing-v2-specific cropping\n",
    "    # img = cv2.resize(img, dsize=(84, 84)) # or you can simply use rescaling\n",
    "    \n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "    return img\n",
    "\n",
    "@nb.njit(fastmath=True)\n",
    "def rgb_to_grey(img):\n",
    "    \"\"\"\n",
    "    Convert an RGB image to greyscale using the weighted method.\n",
    "    \"\"\"\n",
    "    num_rows, num_cols, _ = img.shape\n",
    "    grey_img = np.empty((num_rows, num_cols), dtype=np.uint8)\n",
    "    for i, row in enumerate(img):\n",
    "        for j, rgb_pixel in enumerate(row):\n",
    "            # Compute weighted sum of RGB channels\n",
    "            grey_img[i, j] = 0.2989 * rgb_pixel[0] + 0.5870 * rgb_pixel[1] + 0.1140 * rgb_pixel[2]\n",
    "\n",
    "    return grey_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEnv(gym.Wrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        skip_frames=4,\n",
    "        stack_frames=4,\n",
    "        initial_no_op=50,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(ImageEnv, self).__init__(env, **kwargs)\n",
    "        self.initial_no_op = initial_no_op\n",
    "        self.skip_frames = skip_frames\n",
    "        self.stack_frames = stack_frames\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        # reset the original environment\n",
    "        s, info = self.env.reset()\n",
    "\n",
    "        # Do nothing for the next `self.initial_no_op` steps\n",
    "        for i in range(self.initial_no_op):\n",
    "            s, r, terminated, truncated, info = self.env.step(0)\n",
    "\n",
    "        # crop image\n",
    "        s = crop(s)\n",
    "        s = rgb_to_grey(s)\n",
    "        \n",
    "\n",
    "        # initial observation is simply a copy of the frame 's'\n",
    "        self.stacked_state = np.tile(s, (self.stack_frames, 1, 1))\n",
    "        return self.stacked_state, info\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Take an action for self.skip_frames steps\n",
    "        reward = 0\n",
    "        for _ in range(self.skip_frames):\n",
    "            s, r, terminated, truncated, info = self.env.step(action)\n",
    "            reward += r\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        s = crop(s)\n",
    "        s = rgb_to_grey(s)\n",
    "\n",
    "        # push the current frame 's' at the end of self.stacked_state\n",
    "        self.stacked_state = np.concatenate((self.stacked_state[1:], s[np.newaxis]), axis=0)\n",
    "\n",
    "        return self.stacked_state, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of an observation:  (4, 84, 84)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v2', continuous=False)\n",
    "env = ImageEnv(env)\n",
    "\n",
    "s, _ = env.reset()\n",
    "print(\"The shape of an observation: \", s.shape)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for i in range(4):\n",
    "    axes[i].imshow(s[i], cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNActionValue(tf.keras.Model):\n",
    "    def __init__(self, state_dim, action_dim, activation=tf.nn.relu):\n",
    "        super(CNNActionValue, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(16, kernel_size=8, strides=4, input_shape=state_dim) # [N, 4, 84, 84] -> [N, 16, 20, 20]\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, kernel_size=4, strides=2) # [N, 16, 20, 20] -> [N, 32, 9, 9]\n",
    "        # self.conv1 = tf.keras.layers.Conv2D(16, (8, 8), strides=4, activation='relu', input_shape=state_dim)\n",
    "        # self.conv2 = tf.keras.layers.Conv2D(32, (4, 4), strides=2, activation='relu')\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(256, activation=activation)\n",
    "        self.fc2 = tf.keras.layers.Dense(action_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.nn.relu(self.conv1(x))\n",
    "        x = tf.nn.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Generate some random input data\n",
    "# input_data = np.random.rand(32, 84, 84, 4).astype(np.float32)\n",
    "\n",
    "# input_data = tf.convert_to_tensor(input_data)\n",
    "\n",
    "# # Step 2: Instantiate the model\n",
    "# model = CNNActionValue(state_dim=(4, 84, 84), action_dim=10)\n",
    "\n",
    "# # Step 3: Test the model's output\n",
    "# output = model.call(input_data)\n",
    "# assert output.shape == (32, 10), f\"Expected output shape (32, 10), but got {output.shape}\"\n",
    "\n",
    "# # Step 4: Test the model's differentiability\n",
    "# with tf.GradientTape() as tape:\n",
    "#     tape.watch(input_data)\n",
    "#     output = model.call(input_data)\n",
    "# grads = tape.gradient(output, input_data)\n",
    "# assert grads.shape == input_data.shape, f\"Expected gradient shape {input_data.shape}, but got {grads.shape}\"\n",
    "\n",
    "# # Step 5: Update the model parameters\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "# for i in range(10):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         tape.watch(model.trainable_variables)\n",
    "#         output = model.call(input_data)\n",
    "#         loss = tf.reduce_mean(output)\n",
    "#     grads = tape.gradient(loss, model.trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "#     # Step 6: Repeat the process for a few iterations\n",
    "#     print(f\"Iteration {i+1}: Loss={loss.numpy():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, state_dim, action_dim, max_size=int(1e5)):\n",
    "        self.s = np.zeros((max_size, *state_dim), dtype=np.float32)\n",
    "        self.a = np.zeros((max_size, *action_dim), dtype=np.int64)\n",
    "        self.r = np.zeros((max_size, 1), dtype=np.float32)\n",
    "        self.s_prime = np.zeros((max_size, *state_dim), dtype=np.float32)\n",
    "        self.terminated = np.zeros((max_size, 1), dtype=np.float32)\n",
    "\n",
    "        self.ptr = 0\n",
    "        self.size = 0\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def update(self, s, a, r, s_prime, terminated):\n",
    "        self.s[self.ptr] = s\n",
    "        self.a[self.ptr] = a\n",
    "        self.r[self.ptr] = r\n",
    "        self.s_prime[self.ptr] = s_prime\n",
    "        self.terminated[self.ptr] = terminated\n",
    "        \n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        ind = np.random.randint(0, self.size, batch_size)\n",
    "        return (\n",
    "            tf.constant(self.s[ind], dtype=tf.float32),\n",
    "            tf.constant(self.a[ind], dtype=tf.int32),\n",
    "            tf.constant(self.r[ind], dtype=tf.float32),\n",
    "            tf.constant(self.s_prime[ind], dtype=tf.float32),\n",
    "            tf.constant(self.terminated[ind], dtype=tf.float32),\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        learning_rate=0.00025,\n",
    "        epsilon=1.0,\n",
    "        epsilon_min=0.1,\n",
    "        gamma=0.99,\n",
    "        batch_size=32,\n",
    "        warmup_steps=5000,\n",
    "        buffer_size=int(1e5),\n",
    "        target_update_interval=10000,\n",
    "    ):\n",
    "        self.action_dim = action_dim\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.target_update_interval = target_update_interval\n",
    "\n",
    "        self.network = CNNActionValue(state_dim, action_dim)\n",
    "        self.target_network = CNNActionValue(state_dim, action_dim)\n",
    "        self.target_network.set_weights(self.network.get_weights())\n",
    "        self.optimizer = tf.keras.optimizers.RMSprop(learning_rate)\n",
    "\n",
    "        self.buffer = ReplayBuffer(state_dim, (1, ), buffer_size)\n",
    "        self.device = tf.device('gpu' if tf.test.is_built_with_cuda() else 'cpu')\n",
    "\n",
    "        self.total_steps = 0\n",
    "        self.epsilon_decay = (epsilon - epsilon_min) / 1e6\n",
    "\n",
    "\n",
    "    # @tf.function\n",
    "    # def act(self, x, training=True):\n",
    "    #     self.network.trainable = training\n",
    "    #     if training and ((np.random.rand() < self.epsilon) or (self.total_steps < self.warmup_steps)):\n",
    "    #         a = np.random.randint(0, self.action_dim)\n",
    "    #     else:\n",
    "    #         x = tf.expand_dims(tf.convert_to_tensor(x, dtype=tf.float32), axis=0)\n",
    "    #         q = self.network(x)\n",
    "    #         a = tf.argmax(q, axis=1).numpy()[0]\n",
    "    #     return a\n",
    "    \n",
    "    def act(self, observation):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.choice(self.action_dim)\n",
    "        else:\n",
    "            state = np.array([observation])\n",
    "            actions = self.q_eval.predict(state)\n",
    "\n",
    "            action = np.argmax(actions)\n",
    "\n",
    "        return action\n",
    "    \n",
    "    # @tf.function\n",
    "    # def act(self, x, training=True):\n",
    "    #     self.network.trainable(training)\n",
    "    #     if training and ((tf.random.uniform([]) < self.epsilon) or (self.total_steps < self.warmup_steps)):\n",
    "    #         a = tf.random.uniform([], maxval=self.action_dim, dtype=tf.int64)\n",
    "    #         # np.random.randint(self.action_dim)\n",
    "    #     else:\n",
    "    #         x = tf.expand_dims(x, axis=0)\n",
    "    #         q = self.network(x)\n",
    "    #         a = tf.argmax(q, axis=-1)\n",
    "    #     return a.numpy()[0]\n",
    "    \n",
    "     # def act(self, state, training=True):\n",
    "    #     if training and np.random.rand() < self.epsilon:\n",
    "    #         # Select a random action with probability epsilon\n",
    "    #         action = np.random.randint(self.action_dim)\n",
    "    #     else:\n",
    "    #         # Select the action with the highest Q-value\n",
    "    #         state = tf.expand_dims(state, axis=0)\n",
    "    #         q_values = self.network(state, training=False)\n",
    "    #         action = tf.argmax(q_values, axis=1).numpy()[0]\n",
    "    #     return action\n",
    "    \n",
    "    \n",
    "    # def act(self, x, training=True):\n",
    "    #     if not training:\n",
    "    #         tf.keras.backend.set_learning_phase(False)\n",
    "    #     else:\n",
    "    #         tf.keras.backend.set_learning_phase(True)\n",
    "\n",
    "    #     if training and ((np.random.rand() < self.epsilon) or (self.total_steps < self.warmup_steps)):\n",
    "    #         a = np.random.randint(0, self.action_dim)\n",
    "    #     else:\n",
    "    #         x = tf.expand_dims(tf.convert_to_tensor(x, dtype=tf.float32), 0)\n",
    "    #         q = self.network(x, training=training)\n",
    "    #         a = tf.argmax(q[0]).numpy()\n",
    "    #     return a\n",
    "\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def learn(self):\n",
    "        s, a, r, s_prime, terminated = self.buffer.sample(self.batch_size)\n",
    "        s = tf.convert_to_tensor(s)\n",
    "        a = tf.convert_to_tensor(a)\n",
    "        r = tf.convert_to_tensor(r)\n",
    "        s_prime = tf.convert_to_tensor(s_prime)\n",
    "        terminated = tf.convert_to_tensor(terminated)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            next_q = self.target_network(s_prime)\n",
    "            td_target = r + (1. - terminated) * self.gamma * tf.reduce_max(next_q, axis=-1, keepdims=True)\n",
    "            q_values = tf.gather_nd(self.network(s), tf.stack((tf.range(a.shape[0]), a[:, 0]), axis=1))\n",
    "            loss = tf.reduce_mean(tf.square(q_values - tf.stop_gradient(td_target)))\n",
    "\n",
    "        gradients = tape.gradient(loss, self.network.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_variables))\n",
    "\n",
    "        result = {\n",
    "            'total_steps': self.total_steps,\n",
    "            'value_loss': loss.numpy(),\n",
    "        }\n",
    "        return result\n",
    "    \n",
    "    def process(self, transition):\n",
    "        result = {}\n",
    "        self.total_steps += 1\n",
    "        self.buffer.update(*transition)\n",
    "\n",
    "        if self.total_steps > self.warmup_steps:\n",
    "            result = self.learn()\n",
    "\n",
    "        if self.total_steps % self.target_update_interval == 0:\n",
    "            self.target_network.set_weights(self.network.get_weights())\n",
    "        self.epsilon -= self.epsilon_decay\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2', continuous=False)\n",
    "env = ImageEnv(env)\n",
    "\n",
    "max_steps = int(250000)\n",
    "eval_interval = 10000\n",
    "state_dim = (4, 84, 84) \n",
    "action_dim = env.action_space.n\n",
    "\n",
    "# network = CNNActionValue(state_dim, action_dim)\n",
    "\n",
    "agent = DQN(state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(n_evals=5):\n",
    "    eval_env = gym.make('CarRacing-v2', continuous=False)\n",
    "    eval_env = ImageEnv(eval_env)\n",
    "    \n",
    "    scores = 0\n",
    "    for i in range(n_evals):\n",
    "        (s, _), done, ret = eval_env.reset(), False, 0\n",
    "        while not done:\n",
    "            a = agent.act(s, training=False)\n",
    "            s_prime, r, terminated, truncated, info = eval_env.step(a)\n",
    "            s = s_prime\n",
    "            ret += r\n",
    "            done = terminated or truncated\n",
    "        scores += ret\n",
    "    return np.round(scores / n_evals, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "\n",
    "# history = {'Step': [], 'AvgReturn': []}\n",
    "\n",
    "# (s, _) = env.reset()\n",
    "# while True:\n",
    "#     a = agent.act(s)\n",
    "#     s_prime, r, terminated, truncated, info = env.step(a)\n",
    "#     result = agent.process((s, a, r, s_prime, terminated))  # You can track q-losses over training from `result` variable.\n",
    "    \n",
    "#     s = s_prime\n",
    "#     if terminated or truncated:\n",
    "#         s, _ = env.reset()\n",
    "        \n",
    "#     if agent.total_steps % eval_interval == 0:\n",
    "#         ret = evaluate()\n",
    "#         history['Step'].append(agent.total_steps)\n",
    "#         history['AvgReturn'].append(ret)\n",
    "        \n",
    "#         clear_output()\n",
    "#         plt.figure(figsize=(8, 5))\n",
    "#         plt.plot(history['Step'], history['AvgReturn'], 'r-')\n",
    "#         plt.xlabel('Step', fontsize=16)\n",
    "#         plt.ylabel('AvgReturn', fontsize=16)\n",
    "#         plt.xticks(fontsize=14)\n",
    "#         plt.yticks(fontsize=14)\n",
    "#         plt.grid(axis='y')\n",
    "#         plt.show()\n",
    "        \n",
    "#         agent.network.save_weights('dqn.h5')\n",
    "    \n",
    "#     if agent.total_steps > max_steps:\n",
    "#         break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = gym.make('CarRacing-v2', continuous=False, render_mode='rgb_array')\n",
    "eval_env = ImageEnv(eval_env)\n",
    "\n",
    "frames = []\n",
    "scores = 0\n",
    "(s, _), done, ret = eval_env.reset(), False, 0\n",
    "while not done:\n",
    "    frames.append(eval_env.render())\n",
    "    s = s.astype(np.float32)\n",
    "    a = agent.act(s)\n",
    "    s_prime, r, terminated, truncated, info = eval_env.step(a)\n",
    "    s = s_prime\n",
    "    ret += r\n",
    "    done = terminated or truncated\n",
    "scores += ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(imgs, video_name, _return=True):\n",
    "    import cv2\n",
    "    import os\n",
    "    import string\n",
    "    import random\n",
    "    \n",
    "    if video_name is None:\n",
    "        video_name = ''.join(random.choice(string.ascii_letters) for i in range(18)) + '.mp4'\n",
    "    height, width, layers = imgs[0].shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'VP90')\n",
    "    video = cv2.VideoWriter(video_name, fourcc, 10, (width, height))\n",
    "    \n",
    "    for img in imgs:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        video.write(img)\n",
    "    video.release()\n",
    "    if _return:\n",
    "        from IPython.display import Video\n",
    "        return Video(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"my_video.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animate(frames, \"my_video.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
